data <- data[!is.na(data[,'SID']),]
names(data)<- c("Date_Time","Temp","UOM","ProbeID","SID","Collector")
n <- dim(data)[1] # number of rows in the csv file
for (i in 1:n){
data[i,'Date_Time'] <- csv_to_db_datetime(data[i,'Date_Time']);
}
#reorder by column name for insert to match the SQLite DB
data <- data[c("ProbeID", "SID", "Date_Time","Temp","UOM","Collector")]
#return TRUE is all rows were entered, Error otherwise, ALL OR NOTHING
dbWriteTable(db,'probe_temps', data, append=T); #all or nothing append!!!
#insert data into the DB=====================================
count=count+1
}
#If Error - Identify File####
files[count+1]#File with Error
files[1:count]#Files that were successfully uploaded
csv_dir <- 'S:/M_Kozlak/Temperature/TemperatureDB/DataForUpload/Uploaded/Spring2015/Uploaded/'
files <- list.files(csv_dir,'*.csv'); #only csv files extensions
m <- length(files);
count=0
for(j in 1:m){ #for each csv files in the directory
data <- read.table(paste(csv_dir,files[j],sep=''),sep=',',header=T, stringsAsFactors=F,
na.strings=c("","NA"));
data <- data[!is.na(data[,'SID']),]
names(data)<- c("Date_Time","Temp","UOM","ProbeID","SID","Collector")
n <- dim(data)[1] # number of rows in the csv file
for (i in 1:n){
data[i,'Date_Time'] <- csv_to_db_datetime(data[i,'Date_Time']);
}
#reorder by column name for insert to match the SQLite DB
data <- data[c("ProbeID", "SID", "Date_Time","Temp","UOM","Collector")]
#return TRUE is all rows were entered, Error otherwise, ALL OR NOTHING
dbWriteTable(db,'probe_temps', data, append=T); #all or nothing append!!!
#insert data into the DB=====================================
count=count+1
}
#If Error - Identify File####
files[count+1]#File with Error
files[1:count]#Files that were successfully uploaded
csv_dir <- 'S:/M_Kozlak/Temperature/TemperatureDB/DataForUpload/Uploaded/Spring2015/Uploaded/'
files <- list.files(csv_dir,'*.csv'); #only csv files extensions
m <- length(files);
count=0
for(j in 1:m){ #for each csv files in the directory
data <- read.table(paste(csv_dir,files[j],sep=''),sep=',',header=T, stringsAsFactors=F,
na.strings=c("","NA"));
data <- data[!is.na(data[,'SID']),]
names(data)<- c("Date_Time","Temp","UOM","ProbeID","SID","Collector")
n <- dim(data)[1] # number of rows in the csv file
for (i in 1:n){
data[i,'Date_Time'] <- csv_to_db_datetime(data[i,'Date_Time']);
}
#reorder by column name for insert to match the SQLite DB
data <- data[c("ProbeID", "SID", "Date_Time","Temp","UOM","Collector")]
#return TRUE is all rows were entered, Error otherwise, ALL OR NOTHING
dbWriteTable(db,'probe_temps', data, append=T); #all or nothing append!!!
#insert data into the DB=====================================
count=count+1
}
#If Error - Identify File####
files[count+1]#File with Error
files[1:count]#Files that were successfully uploaded
csv_dir <- 'S:/M_Kozlak/Temperature/TemperatureDB/DataForUpload/Uploaded/Spring2015/Uploaded/'
files <- list.files(csv_dir,'*.csv'); #only csv files extensions
m <- length(files);
count=0
for(j in 1:m){ #for each csv files in the directory
data <- read.table(paste(csv_dir,files[j],sep=''),sep=',',header=T, stringsAsFactors=F,
na.strings=c("","NA"));
data <- data[!is.na(data[,'SID']),]
names(data)<- c("Date_Time","Temp","UOM","ProbeID","SID","Collector")
n <- dim(data)[1] # number of rows in the csv file
for (i in 1:n){
data[i,'Date_Time'] <- csv_to_db_datetime(data[i,'Date_Time']);
}
#reorder by column name for insert to match the SQLite DB
data <- data[c("ProbeID", "SID", "Date_Time","Temp","UOM","Collector")]
#return TRUE is all rows were entered, Error otherwise, ALL OR NOTHING
dbWriteTable(db,'probe_temps', data, append=T); #all or nothing append!!!
#insert data into the DB=====================================
count=count+1
}
#If Error - Identify File####
files[count+1]#File with Error
files[1:count]#Files that were successfully uploaded
csv_dir <- 'S:/M_Kozlak/Temperature/TemperatureDB/DataForUpload/Uploaded/Spring2015/Uploaded/'
files <- list.files(csv_dir,'*.csv'); #only csv files extensions
m <- length(files);
count=0
for(j in 1:m){ #for each csv files in the directory
data <- read.table(paste(csv_dir,files[j],sep=''),sep=',',header=T, stringsAsFactors=F,
na.strings=c("","NA"));
data <- data[!is.na(data[,'SID']),]
names(data)<- c("Date_Time","Temp","UOM","ProbeID","SID","Collector")
n <- dim(data)[1] # number of rows in the csv file
for (i in 1:n){
data[i,'Date_Time'] <- csv_to_db_datetime(data[i,'Date_Time']);
}
#reorder by column name for insert to match the SQLite DB
data <- data[c("ProbeID", "SID", "Date_Time","Temp","UOM","Collector")]
#return TRUE is all rows were entered, Error otherwise, ALL OR NOTHING
dbWriteTable(db,'probe_temps', data, append=T); #all or nothing append!!!
#insert data into the DB=====================================
count=count+1
}
#If Error - Identify File####
files[count+1]#File with Error
files[1:count]#Files that were successfully uploaded
csv_dir <- 'S:/M_Kozlak/Temperature/TemperatureDB/DataForUpload/Uploaded/Spring2015/Uploaded/'
files <- list.files(csv_dir,'*.csv'); #only csv files extensions
m <- length(files);
count=0
for(j in 1:m){ #for each csv files in the directory
data <- read.table(paste(csv_dir,files[j],sep=''),sep=',',header=T, stringsAsFactors=F,
na.strings=c("","NA"));
data <- data[!is.na(data[,'SID']),]
names(data)<- c("Date_Time","Temp","UOM","ProbeID","SID","Collector")
n <- dim(data)[1] # number of rows in the csv file
for (i in 1:n){
data[i,'Date_Time'] <- csv_to_db_datetime(data[i,'Date_Time']);
}
#reorder by column name for insert to match the SQLite DB
data <- data[c("ProbeID", "SID", "Date_Time","Temp","UOM","Collector")]
#return TRUE is all rows were entered, Error otherwise, ALL OR NOTHING
dbWriteTable(db,'probe_temps', data, append=T); #all or nothing append!!!
#insert data into the DB=====================================
count=count+1
}
#If Error - Identify File####
files[count+1]#File with Error
files[1:count]#Files that were successfully uploaded
csv_dir <- 'S:/M_Kozlak/Temperature/TemperatureDB/DataForUpload/Uploaded/Spring2015/Uploaded/'
files <- list.files(csv_dir,'*.csv'); #only csv files extensions
m <- length(files);
count=0
for(j in 1:m){ #for each csv files in the directory
data <- read.table(paste(csv_dir,files[j],sep=''),sep=',',header=T, stringsAsFactors=F,
na.strings=c("","NA"));
data <- data[!is.na(data[,'SID']),]
names(data)<- c("Date_Time","Temp","UOM","ProbeID","SID","Collector")
n <- dim(data)[1] # number of rows in the csv file
for (i in 1:n){
data[i,'Date_Time'] <- csv_to_db_datetime(data[i,'Date_Time']);
}
#reorder by column name for insert to match the SQLite DB
data <- data[c("ProbeID", "SID", "Date_Time","Temp","UOM","Collector")]
#return TRUE is all rows were entered, Error otherwise, ALL OR NOTHING
dbWriteTable(db,'probe_temps', data, append=T); #all or nothing append!!!
#insert data into the DB=====================================
count=count+1
}
#If Error - Identify File####
files[count+1]#File with Error
files[1:count]#Files that were successfully uploaded
csv_dir <- 'S:/M_Kozlak/Temperature/TemperatureDB/DataForUpload/Uploaded/Spring2015/Uploaded/'
files <- list.files(csv_dir,'*.csv'); #only csv files extensions
m <- length(files);
count=0
for(j in 1:m){ #for each csv files in the directory
data <- read.table(paste(csv_dir,files[j],sep=''),sep=',',header=T, stringsAsFactors=F,
na.strings=c("","NA"));
data <- data[!is.na(data[,'SID']),]
names(data)<- c("Date_Time","Temp","UOM","ProbeID","SID","Collector")
n <- dim(data)[1] # number of rows in the csv file
for (i in 1:n){
data[i,'Date_Time'] <- csv_to_db_datetime(data[i,'Date_Time']);
}
#reorder by column name for insert to match the SQLite DB
data <- data[c("ProbeID", "SID", "Date_Time","Temp","UOM","Collector")]
#return TRUE is all rows were entered, Error otherwise, ALL OR NOTHING
dbWriteTable(db,'probe_temps', data, append=T); #all or nothing append!!!
#insert data into the DB=====================================
count=count+1
}
#If Error - Identify File####
files[count+1]#File with Error
files[1:count]#Files that were successfully uploaded
dbDisconnect(db);
library('RSQLite')
library('stringr')
#tested
#yields a datetime ISO8601 string = YYYY-MM-DD HH:MM:SS.SSS
csv_to_db_datetime<-function(Date_Time){
#comes in in the form: "M||M/DD/YYYY HH:MM" -> YYYY-MM-DD HH:MM:SS
csv_datetime <- as.character(Date_Time);
csv_datetime <- strsplit(csv_datetime,' '); # first split by the whitespace between YYYY and HH
csv_date  <- csv_datetime[[1]][1];
csv_date  <- strsplit(csv_date,'/'); #now split by / for D/M/Y
dates <- c(csv_date[[1]][3],csv_date[[1]][1],csv_date[[1]][2]);
dates <- str_pad(dates,2,pad='0');
csv_time   <- csv_datetime[[1]][2];
csv_time   <- strsplit(csv_time,':'); #now split
times <- c(csv_time[[1]][1],csv_time[[1]][2]);
times <- str_pad(times,2,pad='0');
sql_date_time <- paste(paste(dates[1],dates[2],dates[3],sep='-'),paste(times[1],times[2],sep=':'));
sql_date_time <- paste(sql_date_time,':00',sep='');
sql_date_time #return YY-MM-DD HH:MM:SS
}
db_path <- 'S:/M_Kozlak/Temperature/TemperatureDB/'
db <- dbConnect(SQLite(), dbname=paste(db_path,"stream.temperature.sqlite",sep=''));
SQL<- "SELECT ProbeID, SID,min(Date_Time) as Date_Time,max(Date_Time) as Date_Time
FROM probe_temps
GROUP BY ProbeID,SID;"
rows.bfupld <- dbGetQuery(conn=db,SQL); #returns data.frame
rows.bfupld.cnt <-dim(rows.bfupld)
rows.bfupld.cnt[1]
csv_dir <- 'S:/M_Kozlak/Temperature/TemperatureDB/DataForUpload/Uploaded/Fall2017/'
files <- list.files(csv_dir,'*.csv'); #only csv files extensions
m <- length(files);
count=0
for(j in 1:m){ #for each csv files in the directory
data <- read.table(paste(csv_dir,files[j],sep=''),sep=',',header=T, stringsAsFactors=F,
na.strings=c("","NA"));
data <- data[!is.na(data[,'SID']),]
names(data)<- c("Date_Time","Temp","UOM","ProbeID","SID","Collector","ProbeType")
n <- dim(data)[1] # number of rows in the csv file
for (i in 1:n){
data[i,'Date_Time'] <- csv_to_db_datetime(data[i,'Date_Time']);
}
#reorder by column name for insert to match the SQLite DB
data <- data[c("ProbeID", "SID", "Date_Time","Temp","UOM","Collector","ProbeType")]
#return TRUE is all rows were entered, Error otherwise, ALL OR NOTHING
dbWriteTable(db,'probe_temps', data, append=T); #all or nothing append!!!
#insert data into the DB=====================================
count=count+1
}
#If Error - Identify File####
files[count+1]#File with Error
files[1:count]#Files that were successfully uploaded
SQL <- "SELECT ProbeID, SID,min(Date_Time) as Date_Time,max(Date_Time) as Date_Time
FROM probe_temps
WHERE ProbeID == '10777317'"
response <- dbGetQuery(conn=db,SQL); #returns data.frame
response
csv_dir <- 'S:/M_Kozlak/Temperature/TemperatureDB/DataForUpload/Uploaded/Fall2017/'
files <- list.files(csv_dir,'*.csv'); #only csv files extensions
m <- length(files);
count=0
for(j in 1:m){ #for each csv files in the directory
data <- read.table(paste(csv_dir,files[j],sep=''),sep=',',header=T, stringsAsFactors=F,
na.strings=c("","NA"));
data <- data[!is.na(data[,'SID']),]
names(data)<- c("Date_Time","Temp","UOM","ProbeID","SID","Collector","ProbeType")
n <- dim(data)[1] # number of rows in the csv file
for (i in 1:n){
data[i,'Date_Time'] <- csv_to_db_datetime(data[i,'Date_Time']);
}
#reorder by column name for insert to match the SQLite DB
data <- data[c("ProbeID", "SID", "Date_Time","Temp","UOM","Collector","ProbeType")]
#return TRUE is all rows were entered, Error otherwise, ALL OR NOTHING
dbWriteTable(db,'probe_temps', data, append=T); #all or nothing append!!!
#insert data into the DB=====================================
count=count+1
}
#If Error - Identify File####
files[count+1]#File with Error
files[1:count]#Files that were successfully uploaded
SQL<- "SELECT ProbeID, SID,min(Date_Time) as Date_Time,max(Date_Time) as Date_Time
FROM probe_temps
GROUP BY ProbeID,SID;"
rows.bfupld <- dbGetQuery(conn=db,SQL); #returns data.frame
rows.bfupld.cnt <-dim(rows.bfupld)
rows.bfupld.cnt[1]
dbDisconnect(db);
db_path <- 'S:/M_Kozlak/Temperature/TemperatureDB/'
db <- dbConnect(SQLite(), dbname=paste(db_path,"stream.temperature.sqlite",sep=''));
#Identify and Cnt the Rows Before Upload of Unique Launch by Site##############
SQL<- "SELECT ProbeID, SID,min(Date_Time) as Date_Time,max(Date_Time) as Date_Time
FROM probe_temps
GROUP BY ProbeID,SID;"
rows.bfupld <- dbGetQuery(conn=db,SQL); #returns data.frame
rows.bfupld.cnt <-dim(rows.bfupld)
rows.bfupld.cnt[1]
csv_dir <- 'S:/M_Kozlak/Temperature/TemperatureDB/DataForUpload/Uploaded/Spring2018/'
files <- list.files(csv_dir,'*.csv'); #only csv files extensions
m <- length(files);
count=0
for(j in 1:m){ #for each csv files in the directory
data <- read.table(paste(csv_dir,files[j],sep=''),sep=',',header=T, stringsAsFactors=F,
na.strings=c("","NA"));
data <- data[!is.na(data[,'SID']),]
names(data)<- c("Date_Time","Temp","UOM","ProbeID","SID","Collector","ProbeType")
n <- dim(data)[1] # number of rows in the csv file
for (i in 1:n){
data[i,'Date_Time'] <- csv_to_db_datetime(data[i,'Date_Time']);
}
#reorder by column name for insert to match the SQLite DB
data <- data[c("ProbeID", "SID", "Date_Time","Temp","UOM","Collector","ProbeType")]
#return TRUE is all rows were entered, Error otherwise, ALL OR NOTHING
dbWriteTable(db,'probe_temps', data, append=T); #all or nothing append!!!
#insert data into the DB=====================================
count=count+1
}
#If Error - Identify File####
files[count+1]#File with Error
files[1:count]#Files that were successfully uploaded
dbDisconnect(db);
library(RSQLite)
library(plyr)
library(ggplot2)
db_path <- 'S:/M_Kozlak/Temperature/TemperatureDB/' #on windows like this
db <- dbConnect(SQLite(), dbname=paste(db_path,"stream.temperature.sqlite",sep=''));
names  <- dbListTables(db);                        # The tables in the database
fields <- dbListFields(db, "probe_temps");    # The columns in a table
table  <- dbReadTable(db, "probe_temps");  # get the whole table as a data.frame
dim(table)
table$day <- substr(table$Date_Time,6,10)##Add column of data that includes month_day
table$month<- substr(table$Date_Time,6,7)##Add column of data that includes month
table$year<- substr(table$Date_Time,1,4)##Add column of data that includes year
AvgDay <- ddply(table,c("ProbeID","SID","day","month","year","Collector","UOM"),summarize,mean=mean(Temp),min=min(Temp),
max=max(Temp),maxmin= (max(Temp)-min(Temp)),N=length(Temp))#AvgByDay
AvgDay$Flag [AvgDay$N<24|AvgDay$min<0|AvgDay$maxmin>5|AvgDay$mean>=30]<-1
write.csv(AvgDay,"S:/M_Kozlak/Temperature/TemperatureDB/Summary_DB/TempAvgDay.csv",row.names=FALSE)
AvgDay[1:10,]
Flag<- AvgDay[,c(1:5,13)]
Flag[1:10,]
SHEDS<- merge(x=table,y=Flag,by=c("ProbeID","SID","day","month","year"),all.x=TRUE)
SHEDS[1:10,]
SHEDS[100:10,]
SHEDS[100:110,]
AvgDay[AvgDay$mean>=30,]
SHEDS[SHEDS$Temp>=35,]
SHEDS<- SHEDS[is.na(SHEDS[,'Flag']),]
SHEDS<- SHEDS[which(SHEDS$year==2017& SHEDS$Collector=='ABM'),]
dim(SHEDS)
SHEDS[1:10,]
SHEDS[100:110,]
SHEDS[60000:60010,]
SHEDS<- SHEDS[,c(2,6,7)]
write.csv(SHEDS,"S:/M_Kozlak/Temperature/TemperatureDB/Summary_DB/TemperatureDataForSHEDS_083018.csv",row.names=FALSE)
SHEDSSID<-unique(SHEDS$SID)
SHEDSSID
write.csv(SHEDSSID,"SIDForSheds083018.csv")
dim(SHEDS)
686491/3
686491/3*2
write.csv(SHEDS[1:228830,],"S:/M_Kozlak/Temperature/TemperatureDB/Summary_DB/TemperatureDataForSHEDS_083018a.csv",row.names=FALSE)
write.csv(SHEDS[228831:457660,],"S:/M_Kozlak/Temperature/TemperatureDB/Summary_DB/TemperatureDataForSHEDS_083018b.csv",row.names=FALSE)
write.csv(SHEDS[457661:686491,],"S:/M_Kozlak/Temperature/TemperatureDB/Summary_DB/TemperatureDataForSHEDS_083018c.csv",row.names=FALSE)
dbDisconnect(db);
library(RSQLite)
library(plyr)
library(ggplot2)
#open ODBC
db_path <- 'S:/M_Kozlak/Temperature/TemperatureDB/' #on windows like this
db <- dbConnect(SQLite(), dbname=paste(db_path,"stream.temperature.sqlite",sep=''));
names  <- dbListTables(db);                        # The tables in the database
fields <- dbListFields(db, "probe_temps");    # The columns in a table
table  <- dbReadTable(db, "probe_temps");  # get the whole table as a data.frame
SHEDS<-SHEDS[order(SHEDS$SID,SHEDS$Date_Time),]
SHEDS[SHEDS$SID==16139,]
setwd("P:/Projects/GitHub_Prj/SeasonalProductivity")
library(vegan)
library(reshape2)
library(dplyr)
library(lattice)
library(ggplot2)
library(lubridate)
SPP<- read.csv("data/SPP.csv",header=TRUE,row.names=1)
SPP[is.na(SPP)] <- 0
sites<- read.csv("data/sites.csv",header=TRUE)
sites$Collect_Date<-paste0(substr(sites$Collect_Date,6,9),"-0",
substr(sites$Collect_Date,1,1),"-",
substr(sites$Collect_Date,3,4))
#sites$Collect_Date<-as_date(sites$Collect_Date)
sites$month<-as.numeric(substr(sites$SID,4,4))
SPP<- decostand(SPP,"hellinger")#Sqrt of rel abundance
SPP.dist <- vegdist(SPP,"bray")
SPP.dist<-as.matrix(SPP.dist)
levelplot(SPP.dist,at=seq(0,1,0.01),
col.regions=topo.colors(100),scales=list(cex=0.4),
xlab="",ylab="",main="Percent Difference Coefficient (Bray Curtis)")
SPDist<- melt(as.matrix(SPP.dist),varnames=c("SID","col"))
write.csv(SPDist,"SPBCDist.csv")
SPDist<-merge(sites,SPDist,by="SID")
SPDist$CSID<-substr(SPDist$col,1,3)
SPDist$RSID<-substr(SPDist$SID,1,3)
SPDist$MS1<-as.numeric(substr(SPDist$SID,4,4))
SPDist$MS2<-as.numeric(substr(SPDist$col,4,4))
SPDist<-SPDist[which(SPDist$MS1-SPDist$MS2==0 & SPDist$CSID!=SPDist$RSID),]
site.comb<-SPDist[,6:7]
site.comb<-unique(site.comb[c("RSID","CSID")])
site.comb$mean<- 0
SPDist
site.comb<-SPDist[,8:9]
site.comb<-unique(site.comb[c("RSID","CSID")])
site.comb$mean<- 0
names(SPDist)
site.comb<-SPDist[,10:11]
site.comb<-unique(site.comb[c("RSID","CSID")])
site.comb$mean<- 0
site.comb
for (i in 1:dim(site.comb)[1]) {
s<- site.comb[i,]
c<-SPDist[which(SPDist$CSID==s$CSID[1] & SPDist$RSID==s$RSID[1]),]
c<-c[which(c$value!=0),]
m<-mean(c$value)
site.comb$mean[i]<-m
}
site.comb
SPDist
site.comb
SPDist[which(SPDist$RSID=='NOR'&SPDist$CSID=='PEQ'),]
ggplot(BTWSiteDist,aew(x=month,y=((1-value)*100)))+
geom_point()+
geom_smooth(method=lm,se=FALSE,colour="black")+
ylim(0,100)+
labs(y ="Species similarity (%)", x="Month",
title=Stream)
BTWSiteDist<- SPDist[which(SPDist$RSID=='NOR'&SPDist$CSID=='PEQ'),]
ggplot(BTWSiteDist,aew(x=month,y=((1-value)*100)))+
geom_point()+
geom_smooth(method=lm,se=FALSE,colour="black")+
ylim(0,100)+
labs(y ="Species similarity (%)", x="Month",
title=Stream)
ggplot(BTWSiteDist,aes(x=month,y=((1-value)*100)))+
geom_point()+
geom_smooth(method=lm,se=FALSE,colour="black")+
ylim(0,100)+
labs(y ="Species similarity (%)", x="Month",
title=Stream)
BTWSiteDist<- SPDist[which(SPDist$RSID=='NOR'&SPDist$CSID=='PEQ'),]
ggplot(BTWSiteDist,aes(x=month,y=((1-value)*100)))+
geom_point()+
geom_smooth(method=lm,se=FALSE,colour="black")+
ylim(0,100)+
labs(y ="Species similarity (%)", x="Month",
title="Norwalk vs. Pequabuck")
BTWSiteDist<- SPDist[which(SPDist$RSID=='SAL'&SPDist$CSID=='PEQ'),]
ggplot(BTWSiteDist,aes(x=month,y=((1-value)*100)))+
geom_point()+
geom_smooth(method=lm,se=FALSE,colour="black")+
ylim(0,100)+
labs(y ="Species similarity (%)", x="Month",
title="Salmon vs. Pequabuck")
sites
BTWsite<- site[Stream=="Pequabuck",]
BTWsite<- sites[Stream=="Pequabuck",]
BTWsite<- sites[sites$Stream=="Pequabuck",]
BTWsite
BTWsite<- sites[sites$Station.ID==1189000,]
BTWsite
BTWSiteDist
BTWSiteDist<-merge(BTWSiteDist,BTWsite,by="Collect_Date")
BTWSiteDist
BTWSiteDist<- SPDist[which(SPDist$RSID=='SAL'&SPDist$CSID=='PEQ'),]
BTWsite<- sites[sites$Station.ID==1189000,]
BTWSiteDist<-merge(BTWSiteDist,BTWsite,by="month")
BTWSiteDist
BTWSiteDist$TPDiff<-abs(SPDist$TP.x-SPDist$TP.y)
BTWSiteDist$TPDiff<-abs(BTWSiteDist$TP.x-BTWSiteDist$TP.y)
BTWSiteDist<- SPDist[which(SPDist$RSID=='SAL'&SPDist$CSID=='PEQ'),]
ggplot(BTWSiteDist,aes(x=TPDiff,y=((1-value)*100)))+
geom_point()+
geom_smooth(method=lm,se=FALSE,colour="black")+
ylim(0,100)+
labs(y ="Species similarity (%)", x="Month",
title="Salmon vs. Pequabuck")
BTWSiteDist<- SPDist[which(SPDist$RSID=='SAL'&SPDist$CSID=='PEQ'),]
BTWsite<- sites[sites$Station.ID==1189000,]
BTWSiteDist<-merge(BTWSiteDist,BTWsite,by="month")
BTWSiteDist$TPDiff<-abs(BTWSiteDist$TP.x-BTWSiteDist$TP.y)
ggplot(BTWSiteDist,aes(x=TPDiff,y=((1-value)*100)))+
geom_point()+
geom_smooth(method=lm,se=FALSE,colour="black")+
ylim(0,100)+
labs(y ="Species similarity (%)", x="Month",
title="Salmon vs. Pequabuck")
BTWSiteDist<- SPDist[which(SPDist$RSID=='NOR'&SPDist$CSID=='PEQ'),]
ggplot(BTWSiteDist,aes(x=month,y=((1-value)*100)))+
geom_point()+
geom_smooth(method=lm,se=FALSE,colour="black")+
ylim(0,100)+
labs(y ="Species similarity (%)", x="Month",
title="Norwalk vs. Pequabuck")
BTWSiteDist<- SPDist[which(SPDist$RSID=='NOR'&SPDist$CSID=='NOR'),]
ggplot(BTWSiteDist,aes(x=month,y=((1-value)*100)))+
geom_point()+
geom_smooth(method=lm,se=FALSE,colour="black")+
ylim(0,100)+
labs(y ="Species similarity (%)", x="Month",
title="Norwalk vs. Pequabuck")
BTWSiteDist<- SPDist[which(SPDist$RSID=='SAL'&SPDist$CSID=='NOR'),]
ggplot(BTWSiteDist,aes(x=month,y=((1-value)*100)))+
geom_point()+
geom_smooth(method=lm,se=FALSE,colour="black")+
ylim(0,100)+
labs(y ="Species similarity (%)", x="Month",
title="Norwalk vs. Pequabuck")
BTWSiteDist<- SPDist[which(SPDist$RSID=='NOR'&SPDist$CSID=='PEQ'),]
ggplot(BTWSiteDist,aes(x=month,y=((1-value)*100)))+
geom_point()+
geom_smooth(method=lm,se=FALSE,colour="black")+
ylim(0,100)+
labs(y ="Species similarity (%)", x="Month",
title="Norwalk vs. Pequabuck")
SPP<- decostand(SPP,"hellinger")#Sqrt of rel abundance
SPP.dist <- vegdist(SPP,"bray")
SPP.dist<-as.matrix(SPP.dist)
levelplot(SPP.dist,at=seq(0,1,0.01),
col.regions=topo.colors(100),scales=list(cex=0.4),
xlab="",ylab="",main="Percent Difference Coefficient (Bray Curtis)")
site.comb
SPDist<- melt(as.matrix(SPP.dist),varnames=c("SID","col"))
SPDist<-merge(sites,SPDist,by="SID")
SPDist$CSID<-substr(SPDist$col,1,3)
SPDist$RSID<-substr(SPDist$SID,1,3)
SPDist$MS1<-as.numeric(substr(SPDist$SID,4,4))
SPDist$MS2<-as.numeric(substr(SPDist$col,4,4))
SPDist<-SPDist[which(SPDist$MS1-SPDist$MS2!=0 & SPDist$CSID==SPDist$RSID),]
SPDist
